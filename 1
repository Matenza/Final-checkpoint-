
import streamlit as st
import pandas as pd
import numpy as np
from datasets import Dataset
from transformers import BartTokenizer, BartForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq
import torch
import nltk
import re
from sklearn.model_selection import train_test_split
import evaluate  # Nouveau package à utiliser à la place de load_metric

# Télécharger la librairie pour tokenizer les phrases
nltk.download('punkt')

# Charger les métriques ROUGE depuis evaluate
metric = evaluate.load('rouge')

# Fonction pour prétraiter le texte (nettoyage)
def clean_text(text):
    text = re.sub(r'\n', ' ', text)
    text = re.sub(r'[#]', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    return text

# Fonction pour préparer les données pour l'entraînement
def preprocess_function(examples, tokenizer):
    inputs = [doc for doc in examples["dialogue"]]
    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)

    # Tokenization des cibles
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(examples["summary"], max_length=128, truncation=True)

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

# Fonction pour calculer les métriques
def compute_metrics(eval_pred, tokenizer):
    predictions, labels = eval_pred
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    decoded_preds = ["\n".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]
    decoded_labels = ["\n".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]

    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)
    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}
    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]
    result["gen_len"] = np.mean(prediction_lens)

    return {k: round(v, 4) for k, v in result.items()}

# Streamlit App
st.title("Entraînement du modèle BART pour la génération de résumé")

# Téléchargement du fichier CSV
uploaded_file = st.file_uploader("test.csv", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    
    # Nettoyage des données
    df['dialogue'] = df['dialogue'].apply(clean_text)
    df['summary'] = df['summary'].apply(clean_text)

    st.write("Aperçu des données :")
    st.write(df.head())

    # Division des données en ensembles d'entraînement, validation, et test
    train, temp = train_test_split(df, test_size=0.3, random_state=42)
    test, val = train_test_split(temp, test_size=0.5, random_state=42)

    # Conversion en Dataset Hugging Face
    train_ds = Dataset.from_pandas(train)
    val_ds = Dataset.from_pandas(val)

    # Chargement du modèle BART
    checkpoint = 'facebook/bart-large-xsum'
    tokenizer = BartTokenizer.from_pretrained(checkpoint)
    model = BartForConditionalGeneration.from_pretrained(checkpoint)

    # Prétraitement des données
    tokenized_train = train_ds.map(lambda examples: preprocess_function(examples, tokenizer), batched=True, remove_columns=['dialogue', 'summary', '__index_level_0__'])
    tokenized_val = val_ds.map(lambda examples: preprocess_function(examples, tokenizer), batched=True, remove_columns=['dialogue', 'summary', '__index_level_0__'])

    # Data collator pour l'entraînement
    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)

    # Paramètres d'entraînement
    training_args = Seq2SeqTrainingArguments(
        output_dir="./results",
        evaluation_strategy="epoch",
        learning_rate=2e-5,
        per_device_train_batch_size=2,
        per_device_eval_batch_size=2,
        weight_decay=0.01,
        save_total_limit=3,
        num_train_epochs=1,
        predict_with_generate=True
    )

    # Initialiser le Trainer
    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_train,
        eval_dataset=tokenized_val,
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=lambda eval_pred: compute_metrics(eval_pred, tokenizer)
    )

    if st.button('Lancer l\'entraînement'):
        with st.spinner('Entraînement du modèle...'):
            trainer.train()

        # Évaluation du modèle après l'entraînement
        st.write("Évaluation sur le jeu de validation :")
        eval_results = trainer.evaluate()
        st.write(eval_results)

        # Afficher les scores ROUGE
        st.write("Scores ROUGE :")
        st.write(f"ROUGE-1: {eval_results['eval_rouge1']}")
        st.write(f"ROUGE-2: {eval_results['eval_rouge2']}")
        st.write(f"ROUGE-L: {eval_results['eval_rougeL']}")

else:
    st.warning("train.csv")
